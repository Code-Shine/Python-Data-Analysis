{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>热水事件</th>\n",
       "      <th>起始数据编号</th>\n",
       "      <th>终止数据编号</th>\n",
       "      <th>开始时间（begin_time）</th>\n",
       "      <th>根据日志判断是否为洗浴（1表示是，0表示否）</th>\n",
       "      <th>洗浴时间点</th>\n",
       "      <th>总用水时长（w_time）</th>\n",
       "      <th>总停顿时长（w_pause_time）</th>\n",
       "      <th>平均停顿时长（avg_pause_time）</th>\n",
       "      <th>停顿次数（pause）</th>\n",
       "      <th>用水时长（use_water_time）</th>\n",
       "      <th>用水/总时长（use_water_rate）</th>\n",
       "      <th>总用水量（w_water）</th>\n",
       "      <th>平均水流量（water_rate）</th>\n",
       "      <th>水流量波动（flow_volatility）</th>\n",
       "      <th>停顿时长波动（pause_volatility）</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>218</td>\n",
       "      <td>344</td>\n",
       "      <td>2014-10-19 08:51:30'</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>591.999998</td>\n",
       "      <td>303.500013</td>\n",
       "      <td>50.583336</td>\n",
       "      <td>6</td>\n",
       "      <td>288.499985</td>\n",
       "      <td>0.487331</td>\n",
       "      <td>12.998333</td>\n",
       "      <td>2.703293</td>\n",
       "      <td>0.870856</td>\n",
       "      <td>650.106848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>569</td>\n",
       "      <td>965</td>\n",
       "      <td>2014-10-19 15:55:23'</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1008.000005</td>\n",
       "      <td>46.499999</td>\n",
       "      <td>46.499999</td>\n",
       "      <td>1</td>\n",
       "      <td>961.500006</td>\n",
       "      <td>0.953869</td>\n",
       "      <td>50.626667</td>\n",
       "      <td>3.159230</td>\n",
       "      <td>0.202300</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1077</td>\n",
       "      <td>1128</td>\n",
       "      <td>2014-10-19 18:21:40'</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>467.999997</td>\n",
       "      <td>269.499987</td>\n",
       "      <td>53.899997</td>\n",
       "      <td>5</td>\n",
       "      <td>198.500010</td>\n",
       "      <td>0.424145</td>\n",
       "      <td>7.087500</td>\n",
       "      <td>2.142317</td>\n",
       "      <td>0.404960</td>\n",
       "      <td>531.384976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1973</td>\n",
       "      <td>2236</td>\n",
       "      <td>2014-10-20 16:42:41'</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>660.999996</td>\n",
       "      <td>23.499993</td>\n",
       "      <td>23.499993</td>\n",
       "      <td>1</td>\n",
       "      <td>637.500003</td>\n",
       "      <td>0.964448</td>\n",
       "      <td>32.193333</td>\n",
       "      <td>3.029961</td>\n",
       "      <td>0.291306</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2320</td>\n",
       "      <td>2435</td>\n",
       "      <td>2014-10-20 18:05:28'</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>550.000005</td>\n",
       "      <td>164.500013</td>\n",
       "      <td>32.900003</td>\n",
       "      <td>5</td>\n",
       "      <td>385.499992</td>\n",
       "      <td>0.700909</td>\n",
       "      <td>13.459167</td>\n",
       "      <td>2.094812</td>\n",
       "      <td>0.395200</td>\n",
       "      <td>180.384977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   热水事件  起始数据编号  终止数据编号      开始时间（begin_time）  根据日志判断是否为洗浴（1表示是，0表示否）  洗浴时间点  \\\n",
       "0     1     218     344  2014-10-19 08:51:30'                       0      8   \n",
       "1     2     569     965  2014-10-19 15:55:23'                       1     15   \n",
       "2     3    1077    1128  2014-10-19 18:21:40'                       0     18   \n",
       "3     4    1973    2236  2014-10-20 16:42:41'                       1     16   \n",
       "4     5    2320    2435  2014-10-20 18:05:28'                       1     18   \n",
       "\n",
       "   总用水时长（w_time）  总停顿时长（w_pause_time）  平均停顿时长（avg_pause_time）  停顿次数（pause）  \\\n",
       "0     591.999998           303.500013               50.583336            6   \n",
       "1    1008.000005            46.499999               46.499999            1   \n",
       "2     467.999997           269.499987               53.899997            5   \n",
       "3     660.999996            23.499993               23.499993            1   \n",
       "4     550.000005           164.500013               32.900003            5   \n",
       "\n",
       "   用水时长（use_water_time）  用水/总时长（use_water_rate）  总用水量（w_water）  \\\n",
       "0            288.499985                0.487331      12.998333   \n",
       "1            961.500006                0.953869      50.626667   \n",
       "2            198.500010                0.424145       7.087500   \n",
       "3            637.500003                0.964448      32.193333   \n",
       "4            385.499992                0.700909      13.459167   \n",
       "\n",
       "   平均水流量（water_rate）  水流量波动（flow_volatility）  停顿时长波动（pause_volatility）  \n",
       "0           2.703293                0.870856                650.106848  \n",
       "1           3.159230                0.202300                  0.000000  \n",
       "2           2.142317                0.404960                531.384976  \n",
       "3           3.029961                0.291306                  0.000000  \n",
       "4           2.094812                0.395200                180.384977  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "# 3）模型构建\n",
    "# 目标：判断是否是洗浴事件，是则1，不是则0\n",
    "# 建立、训练多层神经网络 并完成模型的检验\n",
    "# 选取”候选洗浴事件“的11个属性作为网络的输入，分别为：洗浴时间点、总用水时长、总停顿时长、平均停顿时长、停顿次数、\n",
    "# 用水时长、用水时长/总用水时长、总用水量、平均水流量、水流量波动和停顿时长波动\n",
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import numpy as np\n",
    "\n",
    "# 由于此单元的中间数据处理原书中有问题，所以此处采用书中给的训练数据，和测试数据，旨在测试模型在此数据上的运行\n",
    "inputfile1 = 'train_neural_network_data.xls' # 训练数据\n",
    "inputfile2 = 'test_neural_network_data.xls' # 测试数据\n",
    "testoutputfile = 'test_output_data.xls' #测试数据模型输出文件\n",
    "\n",
    "data_train = pd.read_excel(inputfile1) # 读入训练数据\n",
    "data_test = pd.read_excel(inputfile2) # 读入测试数据\n",
    "\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = data_train.iloc[:,5:17].as_matrix() # 训练样本特征\n",
    "y_train = data_train.iloc[:,4].as_matrix() # 训练样本标签列\n",
    "x_test = data_test.iloc[:,5:17].as_matrix() # 测试样本特征\n",
    "y_test = data_test.iloc[:,4].as_matrix() # 训练样本标签列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "D:\\Anaconda2\\lib\\site-packages\\keras\\models.py:844: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162      \n",
      "Epoch 2/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162        \n",
      "Epoch 3/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162        \n",
      "Epoch 4/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 5/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162      \n",
      "Epoch 6/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 7/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162        \n",
      "Epoch 8/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162        \n",
      "Epoch 9/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162        \n",
      "Epoch 10/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162        \n",
      "Epoch 11/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162        \n",
      "Epoch 12/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162        \n",
      "Epoch 13/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162        \n",
      "Epoch 14/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162        \n",
      "Epoch 15/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 16/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162     \n",
      "Epoch 17/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 18/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162        \n",
      "Epoch 19/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162        \n",
      "Epoch 20/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162        \n",
      "Epoch 21/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162     \n",
      "Epoch 22/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162     \n",
      "Epoch 23/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162        \n",
      "Epoch 24/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162        \n",
      "Epoch 25/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162        \n",
      "Epoch 26/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162        \n",
      "Epoch 27/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162        \n",
      "Epoch 28/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162        \n",
      "Epoch 29/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162        \n",
      "Epoch 30/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 31/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162      \n",
      "Epoch 32/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162        \n",
      "Epoch 33/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 34/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 35/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162      \n",
      "Epoch 36/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162        \n",
      "Epoch 37/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 38/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 39/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 40/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162        \n",
      "Epoch 41/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 42/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162     \n",
      "Epoch 43/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162      \n",
      "Epoch 44/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 45/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 46/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162        \n",
      "Epoch 47/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 48/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 49/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162      \n",
      "Epoch 50/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162        \n",
      "Epoch 51/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 52/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 53/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 54/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 55/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 56/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 57/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162      \n",
      "Epoch 58/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 59/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162        \n",
      "Epoch 60/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 61/1000\n",
      "28/28 [==============================] - ETA: 0s - loss: 1.1921e-0 - 0s - loss: 3.4162         \n",
      "Epoch 62/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 63/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162        \n",
      "Epoch 64/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 65/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162      \n",
      "Epoch 66/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162      \n",
      "Epoch 67/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 68/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 69/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 70/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 71/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162      \n",
      "Epoch 72/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 73/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 74/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 75/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 76/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 77/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 78/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 79/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 80/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 81/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 82/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162      \n",
      "Epoch 83/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162      \n",
      "Epoch 84/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 85/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 86/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 87/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 88/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162      \n",
      "Epoch 89/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 90/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 91/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 92/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 93/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162      \n",
      "Epoch 94/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162      \n",
      "Epoch 95/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162      \n",
      "Epoch 96/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 97/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 98/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162      \n",
      "Epoch 99/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 100/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 101/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 102/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162      \n",
      "Epoch 103/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 104/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 105/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 106/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 107/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162      \n",
      "Epoch 108/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 109/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 110/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 111/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162      \n",
      "Epoch 112/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162        \n",
      "Epoch 113/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162        \n",
      "Epoch 114/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 115/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 116/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 117/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 118/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 119/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162      \n",
      "Epoch 120/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162      \n",
      "Epoch 121/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162      \n",
      "Epoch 122/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 123/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 124/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 125/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 126/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 127/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162      \n",
      "Epoch 128/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 129/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 130/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 131/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 132/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 133/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 134/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 135/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 136/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 137/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 138/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 139/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162      \n",
      "Epoch 140/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 141/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 142/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162        \n",
      "Epoch 143/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 144/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 145/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 146/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 147/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 148/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 149/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162      \n",
      "Epoch 150/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 151/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 152/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 153/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 154/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 155/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 156/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 157/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162      \n",
      "Epoch 158/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 159/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 160/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162      \n",
      "Epoch 161/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 162/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162      \n",
      "Epoch 163/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 164/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 165/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 166/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 167/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 168/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 169/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162      \n",
      "Epoch 170/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 171/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162      \n",
      "Epoch 172/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162     \n",
      "Epoch 173/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162      \n",
      "Epoch 174/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 175/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 176/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 177/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162        \n",
      "Epoch 178/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 179/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 180/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 181/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 182/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162      \n",
      "Epoch 183/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 184/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 185/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 186/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 187/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162      \n",
      "Epoch 188/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 189/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 190/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 191/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 192/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 193/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162      \n",
      "Epoch 194/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 195/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 196/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 197/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 198/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 199/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 200/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 201/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162      \n",
      "Epoch 202/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 203/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 204/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 205/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 206/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162      \n",
      "Epoch 207/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162        \n",
      "Epoch 208/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162        \n",
      "Epoch 209/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 210/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 211/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162        \n",
      "Epoch 212/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 213/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 214/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 215/1000\n",
      "28/28 [==============================] - 0s - loss: 3.4162         \n",
      "Epoch 216/1000\n",
      " 1/28 [>.............................] - ETA: 0s - loss: 1.1921e-07"
     ]
    }
   ],
   "source": [
    "\n",
    "# 训练神经网络时，对神经网络的参数进行寻优，发现含两个隐含层的神经网络训练效果较好\n",
    "# 其中两个隐层的节点数分别为17和10时训练效果较好\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "\n",
    "netfile = 'net.model'# 构建的神经网络模型存储路径\n",
    "\n",
    "model = Sequential() # 建立模型\n",
    "model.add(Dense(units=17, input_dim=11)) # 添加输入层、隐藏层的连接\n",
    "model.add(Activation('relu')) # 以relu函数为激活函数\n",
    "model.add(Dense(units=10, input_dim=17)) # 添加隐藏层、二层隐藏层的连接\n",
    "model.add(Activation('relu')) # 以relu函数为激活函数\n",
    "model.add(Dense(units=1, input_dim=10)) # 添加二层隐藏层、输出层的连接\n",
    "model.add(Activation('sigmoid')) # 以sigmoid函数为激活函数\n",
    "\n",
    "# 编译模型，损失函数为binary_crossentropy,用adam法求解\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam')\n",
    "model.fit(x_train, y_train, nb_epoch = 1000, batch_size = 1)\n",
    "model.save_weights(netfile)# 保存模型参数\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD3CAYAAAD/jPo0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d40898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict_result_train = model.predict_classes(x_train).reshape(len(data_train)) #给出预测类别（训练集）\n",
    "from cm_plot import *\n",
    "cm_plot(y_train, predict_result_train).show() #显示混淆矩阵可视化结果 看训练结果正确率\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>热水事件</th>\n",
       "      <th>起始数据编号</th>\n",
       "      <th>终止数据编号</th>\n",
       "      <th>开始时间（begin_time）</th>\n",
       "      <th>根据日志判断是否为洗浴（1表示是，0表示否）</th>\n",
       "      <th>预测结果</th>\n",
       "      <th>预测正确率</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>336</td>\n",
       "      <td>2015-01-05 9:42:41'</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>420</td>\n",
       "      <td>535</td>\n",
       "      <td>'2015-01-05 18:05:28'</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>538</td>\n",
       "      <td>706</td>\n",
       "      <td>'2015-01-05 18:25:24'</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>793</td>\n",
       "      <td>910</td>\n",
       "      <td>'2015-01-05 20:00:42'</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>935</td>\n",
       "      <td>1133</td>\n",
       "      <td>'2015-01-05 20:15:13'</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1172</td>\n",
       "      <td>1274</td>\n",
       "      <td>'2015-01-05 20:42:41'</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1641</td>\n",
       "      <td>1770</td>\n",
       "      <td>'2015-01-06 08:08:26'</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>2105</td>\n",
       "      <td>2280</td>\n",
       "      <td>2015-01-06 11:31:13'</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>2290</td>\n",
       "      <td>2506</td>\n",
       "      <td>'2015-01-06 17:08:35'</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>2562</td>\n",
       "      <td>2708</td>\n",
       "      <td>'2015-01-06 17:43:48'</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>3141</td>\n",
       "      <td>3284</td>\n",
       "      <td>'2015-01-07 10:01:57'</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>3524</td>\n",
       "      <td>3655</td>\n",
       "      <td>2015-01-07 13:32:43'</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>3659</td>\n",
       "      <td>3863</td>\n",
       "      <td>'2015-01-07 17:48:22'</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>3937</td>\n",
       "      <td>4125</td>\n",
       "      <td>'2015-01-07 18:26:49'</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>4145</td>\n",
       "      <td>4373</td>\n",
       "      <td>'2015-01-07 18:46:07'</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>4411</td>\n",
       "      <td>4538</td>\n",
       "      <td>'2015-01-07 19:18:08'</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>5700</td>\n",
       "      <td>5894</td>\n",
       "      <td>2015-01-08 7:08:43'</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>5913</td>\n",
       "      <td>6178</td>\n",
       "      <td>2015-01-08 13:23:42'</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>6238</td>\n",
       "      <td>6443</td>\n",
       "      <td>2015-01-08 18:06:47'</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>6629</td>\n",
       "      <td>6696</td>\n",
       "      <td>2015-01-08 20:18:58'</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>6713</td>\n",
       "      <td>6879</td>\n",
       "      <td>2015-01-08 20:32:16'</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    热水事件  起始数据编号  终止数据编号       开始时间（begin_time）  根据日志判断是否为洗浴（1表示是，0表示否）  预测结果  \\\n",
       "0      1      73     336    2015-01-05 9:42:41'                       1     1   \n",
       "1      2     420     535  '2015-01-05 18:05:28'                       1     1   \n",
       "2      3     538     706  '2015-01-05 18:25:24'                       1     1   \n",
       "3      4     793     910  '2015-01-05 20:00:42'                       1     1   \n",
       "4      5     935    1133  '2015-01-05 20:15:13'                       1     1   \n",
       "5      6    1172    1274  '2015-01-05 20:42:41'                       1     1   \n",
       "6      7    1641    1770  '2015-01-06 08:08:26'                       0     1   \n",
       "7      8    2105    2280   2015-01-06 11:31:13'                       1     1   \n",
       "8      9    2290    2506  '2015-01-06 17:08:35'                       1     1   \n",
       "9     10    2562    2708  '2015-01-06 17:43:48'                       1     1   \n",
       "10    11    3141    3284  '2015-01-07 10:01:57'                       0     1   \n",
       "11    12    3524    3655   2015-01-07 13:32:43'                       0     1   \n",
       "12    13    3659    3863  '2015-01-07 17:48:22'                       1     1   \n",
       "13    14    3937    4125  '2015-01-07 18:26:49'                       1     1   \n",
       "14    15    4145    4373  '2015-01-07 18:46:07'                       1     1   \n",
       "15    16    4411    4538  '2015-01-07 19:18:08'                       1     1   \n",
       "16    17    5700    5894    2015-01-08 7:08:43'                       0     1   \n",
       "17    18    5913    6178   2015-01-08 13:23:42'                       1     1   \n",
       "18    19    6238    6443   2015-01-08 18:06:47'                       1     1   \n",
       "19    20    6629    6696   2015-01-08 20:18:58'                       1     1   \n",
       "20    21    6713    6879   2015-01-08 20:32:16'                       1     1   \n",
       "\n",
       "    预测正确率  \n",
       "0     1.0  \n",
       "1     1.0  \n",
       "2     1.0  \n",
       "3     1.0  \n",
       "4     1.0  \n",
       "5     1.0  \n",
       "6     1.0  \n",
       "7     1.0  \n",
       "8     1.0  \n",
       "9     1.0  \n",
       "10    1.0  \n",
       "11    1.0  \n",
       "12    1.0  \n",
       "13    1.0  \n",
       "14    1.0  \n",
       "15    1.0  \n",
       "16    1.0  \n",
       "17    1.0  \n",
       "18    1.0  \n",
       "19    1.0  \n",
       "20    1.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "predict_result_test = model.predict_classes(x_test).reshape(len(data_test)) #给出预测类别（测试集）\n",
    "from cm_plot import *\n",
    "cm_plot(y_test, predict_result_test).show() #显示混淆矩阵可视化结果 看训练结果正确率\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = DataFrame(predict_result_test, columns = [u'预测结果']) # 给出预测类别测试集\n",
    "predict_rate = DataFrame(model.predict(x_test), columns = [u'预测正确率']) # 给出预测类别测试集\n",
    "res = pd.concat([data_test.iloc[:,:5],r,predict_rate], axis=1)#测试集\n",
    "res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
